{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison: L1 Minimization vs Polynomial Approximation for Imputation\n",
    "\n",
    "This notebook compares two methods for recovering missing values in signals:\n",
    "\n",
    "1. **L1 Minimization** (Theorem 1.20): Compressed sensing approach with L1 sparsity\n",
    "2. **Polynomial Approximation** (Adaptive): L2 fitting with adaptive frequency selection\n",
    "\n",
    "Both methods are tested on the same dataset with identical missing value patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Import our modules\n",
    "from fourier_core import fourier_ratio\n",
    "from imputation import (\n",
    "    mask_observations,\n",
    "    compute_q,\n",
    "    build_dft_basis,\n",
    "    recover_l1_quadratic_constraint,\n",
    "    recover_polynomial_approx,\n",
    "    check_theorem_bound\n",
    ")\n",
    "from signal_utils import generate_composite_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Test Signal and Simulate Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal parameters\n",
    "sr = 32  # sampling rate (Hz)\n",
    "seconds = 5.0  # duration\n",
    "N = int(sr * seconds)\n",
    "\n",
    "# Generate signal with some noise\n",
    "t, f_full = generate_composite_signal(sr, seconds, noise_std=0.5)\n",
    "\n",
    "# Compute Fourier Ratio\n",
    "FR = fourier_ratio(f_full)\n",
    "print(f\"Signal length N = {N}\")\n",
    "print(f\"Fourier Ratio FR = {FR:.4f}\")\n",
    "print(f\"Interpretation: {'Low complexity (structured signal)' if FR < 5 else 'High complexity'}\")\n",
    "\n",
    "# Plot complete signal\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(t, f_full, 'b-', label='Complete signal', linewidth=1.5)\n",
    "plt.xlabel('Time (s)', fontsize=11)\n",
    "plt.ylabel('Amplitude', fontsize=11)\n",
    "plt.title('Original Complete Signal (with noise)', fontsize=13, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate missing data\n",
    "keep_prob = 0.7  # Keep 70% of observations (30% missing)\n",
    "seed = 42  # for reproducibility\n",
    "\n",
    "mask, f_obs = mask_observations(f_full, keep_prob=keep_prob, seed=seed)\n",
    "\n",
    "num_observed = np.sum(mask)\n",
    "num_missing = np.sum(~mask)\n",
    "missing_rate = num_missing / N * 100\n",
    "\n",
    "print(f\"Total samples: {N}\")\n",
    "print(f\"Observed: {num_observed} ({100-missing_rate:.1f}%)\")\n",
    "print(f\"Missing: {num_missing} ({missing_rate:.1f}%)\")\n",
    "\n",
    "# Visualize observed vs missing\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(t, f_full, 'gray', alpha=0.3, label='True signal (hidden)', linewidth=2)\n",
    "plt.scatter(t[mask], f_obs[mask], c='blue', s=15, label='Observed', zorder=3, alpha=0.7)\n",
    "plt.scatter(t[~mask], f_full[~mask], c='red', s=25, label='Missing (ground truth)', \n",
    "            alpha=0.6, zorder=2, marker='x')\n",
    "plt.xlabel('Time (s)', fontsize=11)\n",
    "plt.ylabel('Amplitude', fontsize=11)\n",
    "plt.title(f'Signal with {missing_rate:.1f}% Missing Values', fontsize=13, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Method 1: L1 Minimization (Compressed Sensing)\n",
    "\n",
    "This method solves an optimization problem:\n",
    "$$\\min \\|\\hat{c}\\|_1 \\text{ subject to } \\|y - A\\hat{c}\\|_{2} \\text{ is small}$$\n",
    "\n",
    "where:\n",
    "- $\\hat{c}$ = Fourier coefficients\n",
    "- $A$ = DFT basis evaluated at observed points\n",
    "- $y$ = observed values\n",
    "- L1 norm promotes sparsity in frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for L1 recovery\n",
    "eps = 0.1  # desired recovery accuracy\n",
    "C = 1.0  # universal constant multiplier\n",
    "\n",
    "# Compute required observations\n",
    "valid_idx = np.where(mask)[0]\n",
    "q = compute_q(FR=FR, eps=eps, N=N, C=C, max_available=len(valid_idx))\n",
    "\n",
    "print(f\"=== L1 Minimization Method ===\")\n",
    "print(f\"Recovery parameters:\")\n",
    "print(f\"  ε (accuracy) = {eps}\")\n",
    "print(f\"  Fourier Ratio = {FR:.4f}\")\n",
    "print(f\"  Theoretical observations needed: q = {q}\")\n",
    "print(f\"  Available observations: {len(valid_idx)}\")\n",
    "\n",
    "# Perform L1 recovery\n",
    "print(f\"\\nPerforming L1 minimization...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Select q observations\n",
    "np.random.seed(seed)\n",
    "obs_idx = np.random.choice(valid_idx, q, replace=False)\n",
    "y = f_obs[obs_idx]\n",
    "\n",
    "# Build DFT basis and measurement matrix\n",
    "B = build_dft_basis(N)\n",
    "A = B[obs_idx, :]\n",
    "\n",
    "# Recover using L1 minimization\n",
    "c_rec = recover_l1_quadratic_constraint(A, y, eps)\n",
    "f_rec_l1 = B @ c_rec\n",
    "f_rec_l1 = f_rec_l1.real  # Take real part\n",
    "\n",
    "l1_time = time.time() - start_time\n",
    "print(f\"✓ L1 recovery completed in {l1_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Method 2: Polynomial Approximation (Adaptive Frequency Selection)\n",
    "\n",
    "This method uses a simpler approach:\n",
    "1. Project observed data onto ALL frequency basis functions\n",
    "2. Select top-k frequencies with largest projection magnitudes\n",
    "3. Refit using least squares (L2): $\\min \\|y - A_{selected}\\hat{c}\\|_2^2$\n",
    "4. Evaluate on full grid\n",
    "\n",
    "**Key difference**: L2 fitting (faster) vs L1 optimization (sparser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"=== Polynomial Approximation Method ===\")\n",
    "print(f\"Using same accuracy parameter: ε = {eps}\")\n",
    "print(f\"\\nPerforming polynomial approximation...\")\n",
    "\n",
    "start_time = time.time()\n",
    "f_rec_poly = recover_polynomial_approx(f_obs, mask, eps=eps)\n",
    "poly_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n✓ Polynomial recovery completed in {poly_time:.3f} seconds\")\n",
    "print(f\"\\nSpeed comparison: Polynomial is {l1_time/poly_time:.1f}x faster than L1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Error Metrics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute comprehensive error metrics for both methods\n",
    "\n",
    "def compute_metrics(f_true, f_pred, mask, method_name):\n",
    "    \"\"\"Compute and display error metrics.\"\"\"\n",
    "    # Overall metrics\n",
    "    mse_full = np.mean((f_true - f_pred) ** 2)\n",
    "    rmse_full = np.sqrt(mse_full)\n",
    "    mae_full = np.mean(np.abs(f_true - f_pred))\n",
    "    rel_err_full = np.linalg.norm(f_true - f_pred) / np.linalg.norm(f_true)\n",
    "    \n",
    "    # Metrics on missing points only\n",
    "    missing_mask = ~mask\n",
    "    mse_missing = np.mean((f_true[missing_mask] - f_pred[missing_mask]) ** 2)\n",
    "    rmse_missing = np.sqrt(mse_missing)\n",
    "    mae_missing = np.mean(np.abs(f_true[missing_mask] - f_pred[missing_mask]))\n",
    "    rel_err_missing = np.linalg.norm(f_true[missing_mask] - f_pred[missing_mask]) / np.linalg.norm(f_true[missing_mask])\n",
    "    \n",
    "    # Metrics on observed points only\n",
    "    mse_obs = np.mean((f_true[mask] - f_pred[mask]) ** 2)\n",
    "    rmse_obs = np.sqrt(mse_obs)\n",
    "    mae_obs = np.mean(np.abs(f_true[mask] - f_pred[mask]))\n",
    "    rel_err_obs = np.linalg.norm(f_true[mask] - f_pred[mask]) / np.linalg.norm(f_true[mask])\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{method_name} - Error Metrics\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"\\n** Full Signal **\")\n",
    "    print(f\"  RMSE:          {rmse_full:.6f}\")\n",
    "    print(f\"  MAE:           {mae_full:.6f}\")\n",
    "    print(f\"  Relative L2:   {rel_err_full:.6f}\")\n",
    "    \n",
    "    print(f\"\\n** Missing Points Only **\")\n",
    "    print(f\"  RMSE:          {rmse_missing:.6f}\")\n",
    "    print(f\"  MAE:           {mae_missing:.6f}\")\n",
    "    print(f\"  Relative L2:   {rel_err_missing:.6f}\")\n",
    "    \n",
    "    print(f\"\\n** Observed Points Only **\")\n",
    "    print(f\"  RMSE:          {rmse_obs:.6f}\")\n",
    "    print(f\"  MAE:           {mae_obs:.6f}\")\n",
    "    print(f\"  Relative L2:   {rel_err_obs:.6f}\")\n",
    "    \n",
    "    return {\n",
    "        'rmse_full': rmse_full,\n",
    "        'mae_full': mae_full,\n",
    "        'rel_err_full': rel_err_full,\n",
    "        'rmse_missing': rmse_missing,\n",
    "        'mae_missing': mae_missing,\n",
    "        'rel_err_missing': rel_err_missing,\n",
    "        'rmse_obs': rmse_obs,\n",
    "        'mae_obs': mae_obs,\n",
    "        'rel_err_obs': rel_err_obs\n",
    "    }\n",
    "\n",
    "# Compute metrics for both methods\n",
    "metrics_l1 = compute_metrics(f_full, f_rec_l1, mask, \"L1 Minimization\")\n",
    "metrics_poly = compute_metrics(f_full, f_rec_poly, mask, \"Polynomial Approximation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison table\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"COMPARISON SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\n{'Metric':<30} {'L1 Minimization':<20} {'Polynomial Approx':<20} {'Winner'}\")\n",
    "print(f\"{'-'*80}\")\n",
    "\n",
    "def compare_metric(name, val1, val2):\n",
    "    if val1 < 1e-10 and val2 < 1e-10:\n",
    "        winner = \"Tie (both near-perfect)\"\n",
    "        ratio = 1.0\n",
    "    elif val1 < val2:\n",
    "        winner = \"L1\"\n",
    "        ratio = val2/val1 if val1 > 1e-10 else float('inf')\n",
    "    else:\n",
    "        winner = \"Polynomial\"\n",
    "        ratio = val1/val2 if val2 > 1e-10 else float('inf')\n",
    "    \n",
    "    if ratio == float('inf'):\n",
    "        print(f\"{name:<30} {val1:<20.6f} {val2:<20.6f} {winner} (perfect)\")\n",
    "    else:\n",
    "        print(f\"{name:<30} {val1:<20.6f} {val2:<20.6f} {winner} ({ratio:.2f}x)\")\n",
    "\n",
    "print(\"\\nFull Signal:\")\n",
    "compare_metric(\"  RMSE\", metrics_l1['rmse_full'], metrics_poly['rmse_full'])\n",
    "compare_metric(\"  MAE\", metrics_l1['mae_full'], metrics_poly['mae_full'])\n",
    "compare_metric(\"  Relative L2 Error\", metrics_l1['rel_err_full'], metrics_poly['rel_err_full'])\n",
    "\n",
    "print(\"\\nMissing Points Only:\")\n",
    "compare_metric(\"  RMSE\", metrics_l1['rmse_missing'], metrics_poly['rmse_missing'])\n",
    "compare_metric(\"  MAE\", metrics_l1['mae_missing'], metrics_poly['mae_missing'])\n",
    "compare_metric(\"  Relative L2 Error\", metrics_l1['rel_err_missing'], metrics_poly['rel_err_missing'])\n",
    "\n",
    "print(\"\\nObserved Points Only:\")\n",
    "compare_metric(\"  RMSE\", metrics_l1['rmse_obs'], metrics_poly['rmse_obs'])\n",
    "compare_metric(\"  MAE\", metrics_l1['mae_obs'], metrics_poly['mae_obs'])\n",
    "compare_metric(\"  Relative L2 Error\", metrics_l1['rel_err_obs'], metrics_poly['rel_err_obs'])\n",
    "\n",
    "print(f\"\\nComputational Time:\")\n",
    "print(f\"  L1 Minimization:         {l1_time:.3f} seconds\")\n",
    "print(f\"  Polynomial Approximation: {poly_time:.3f} seconds\")\n",
    "print(f\"  Speedup:                  {l1_time/poly_time:.1f}x\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Full view - L1 Minimization\n",
    "ax = axes[0, 0]\n",
    "ax.plot(t, f_full, 'k-', alpha=0.4, label='True signal', linewidth=2)\n",
    "ax.scatter(t[mask], f_obs[mask], c='blue', s=10, label='Observed', zorder=3, alpha=0.6)\n",
    "ax.plot(t, f_rec_l1, 'r--', label='L1 recovery', linewidth=2, alpha=0.8)\n",
    "ax.set_xlabel('Time (s)', fontsize=10)\n",
    "ax.set_ylabel('Amplitude', fontsize=10)\n",
    "ax.set_title(f'L1 Minimization (RMSE={metrics_l1[\"rmse_full\"]:.4f})', fontsize=11, fontweight='bold')\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Full view - Polynomial Approximation\n",
    "ax = axes[0, 1]\n",
    "ax.plot(t, f_full, 'k-', alpha=0.4, label='True signal', linewidth=2)\n",
    "ax.scatter(t[mask], f_obs[mask], c='blue', s=10, label='Observed', zorder=3, alpha=0.6)\n",
    "ax.plot(t, f_rec_poly, 'g--', label='Polynomial recovery', linewidth=2, alpha=0.8)\n",
    "ax.set_xlabel('Time (s)', fontsize=10)\n",
    "ax.set_ylabel('Amplitude', fontsize=10)\n",
    "ax.set_title(f'Polynomial Approximation (RMSE={metrics_poly[\"rmse_full\"]:.4f})', fontsize=11, fontweight='bold')\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Missing points only - L1\n",
    "ax = axes[1, 0]\n",
    "missing_mask = ~mask\n",
    "ax.scatter(t[missing_mask], f_full[missing_mask], c='black', s=30, \n",
    "           label='True (missing)', marker='o', alpha=0.6, zorder=3)\n",
    "ax.scatter(t[missing_mask], f_rec_l1[missing_mask], c='red', s=30, \n",
    "           label='L1 recovered', marker='x', alpha=0.8, zorder=4)\n",
    "ax.set_xlabel('Time (s)', fontsize=10)\n",
    "ax.set_ylabel('Amplitude', fontsize=10)\n",
    "ax.set_title(f'L1: Missing Points (MAE={metrics_l1[\"mae_missing\"]:.4f})', fontsize=11, fontweight='bold')\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Missing points only - Polynomial\n",
    "ax = axes[1, 1]\n",
    "ax.scatter(t[missing_mask], f_full[missing_mask], c='black', s=30, \n",
    "           label='True (missing)', marker='o', alpha=0.6, zorder=3)\n",
    "ax.scatter(t[missing_mask], f_rec_poly[missing_mask], c='green', s=30, \n",
    "           label='Poly recovered', marker='x', alpha=0.8, zorder=4)\n",
    "ax.set_xlabel('Time (s)', fontsize=10)\n",
    "ax.set_ylabel('Amplitude', fontsize=10)\n",
    "ax.set_title(f'Polynomial: Missing Points (MAE={metrics_poly[\"mae_missing\"]:.4f})', fontsize=11, fontweight='bold')\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Point-wise error - L1\n",
    "ax = axes[2, 0]\n",
    "error_l1 = np.abs(f_full - f_rec_l1)\n",
    "ax.plot(t, error_l1, 'r-', alpha=0.5, linewidth=1)\n",
    "ax.scatter(t[missing_mask], error_l1[missing_mask], c='red', s=20, \n",
    "           label=f'Error at missing (mean={np.mean(error_l1[missing_mask]):.4f})')\n",
    "ax.axhline(y=np.mean(error_l1[missing_mask]), color='darkred', linestyle='--', \n",
    "           linewidth=2, alpha=0.7)\n",
    "ax.set_xlabel('Time (s)', fontsize=10)\n",
    "ax.set_ylabel('Absolute Error', fontsize=10)\n",
    "ax.set_title('L1: Point-wise Absolute Error', fontsize=11, fontweight='bold')\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Point-wise error - Polynomial\n",
    "ax = axes[2, 1]\n",
    "error_poly = np.abs(f_full - f_rec_poly)\n",
    "ax.plot(t, error_poly, 'g-', alpha=0.5, linewidth=1)\n",
    "ax.scatter(t[missing_mask], error_poly[missing_mask], c='green', s=20, \n",
    "           label=f'Error at missing (mean={np.mean(error_poly[missing_mask]):.4f})')\n",
    "ax.axhline(y=np.mean(error_poly[missing_mask]), color='darkgreen', linestyle='--', \n",
    "           linewidth=2, alpha=0.7)\n",
    "ax.set_xlabel('Time (s)', fontsize=10)\n",
    "ax.set_ylabel('Absolute Error', fontsize=10)\n",
    "ax.set_title('Polynomial: Point-wise Absolute Error', fontsize=11, fontweight='bold')\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Direct Side-by-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison on same plot\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# Plot 1: Both methods overlaid\n",
    "ax = axes[0]\n",
    "ax.plot(t, f_full, 'k-', alpha=0.5, label='True signal', linewidth=2.5, zorder=1)\n",
    "ax.scatter(t[mask], f_obs[mask], c='blue', s=15, label='Observed', zorder=4, alpha=0.5)\n",
    "ax.plot(t, f_rec_l1, 'r--', label=f'L1 (RMSE={metrics_l1[\"rmse_full\"]:.4f})', \n",
    "        linewidth=2, alpha=0.8, zorder=2)\n",
    "ax.plot(t, f_rec_poly, 'g-.', label=f'Polynomial (RMSE={metrics_poly[\"rmse_full\"]:.4f})', \n",
    "        linewidth=2, alpha=0.8, zorder=3)\n",
    "ax.set_xlabel('Time (s)', fontsize=12)\n",
    "ax.set_ylabel('Amplitude', fontsize=12)\n",
    "ax.set_title('Both Methods Compared: Full Signal', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Error comparison\n",
    "ax = axes[1]\n",
    "ax.plot(t, error_l1, 'r-', label=f'L1 error (mean={np.mean(error_l1):.4f})', \n",
    "        linewidth=2, alpha=0.7)\n",
    "ax.plot(t, error_poly, 'g-', label=f'Polynomial error (mean={np.mean(error_poly):.4f})', \n",
    "        linewidth=2, alpha=0.7)\n",
    "ax.scatter(t[missing_mask], error_l1[missing_mask], c='darkred', s=15, \n",
    "           label='L1 error at missing', alpha=0.6, zorder=3)\n",
    "ax.scatter(t[missing_mask], error_poly[missing_mask], c='darkgreen', s=15, \n",
    "           label='Poly error at missing', alpha=0.6, zorder=3)\n",
    "ax.set_xlabel('Time (s)', fontsize=12)\n",
    "ax.set_ylabel('Absolute Error', fontsize=12)\n",
    "ax.set_title('Error Comparison: Both Methods', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY: L1 Minimization vs Polynomial Approximation\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n**Signal Properties:**\")\n",
    "print(f\"  Signal length:        {N}\")\n",
    "print(f\"  Fourier Ratio:        {FR:.4f} (lower is more structured)\")\n",
    "print(f\"  Missing rate:         {missing_rate:.1f}%\")\n",
    "print(f\"  Accuracy parameter:   ε = {eps}\")\n",
    "\n",
    "print(f\"\\n**Method Characteristics:**\")\n",
    "print(f\"\\n  L1 Minimization (Theorem 1.20):\")\n",
    "print(f\"    - Approach: Compressed sensing, L1 optimization\")\n",
    "print(f\"    - Observations used: {q} out of {num_observed}\")\n",
    "print(f\"    - Computation time: {l1_time:.3f} seconds\")\n",
    "print(f\"    - Promotes sparsity via L1 norm\")\n",
    "\n",
    "print(f\"\\n  Polynomial Approximation (Adaptive L2):\")\n",
    "print(f\"    - Approach: Adaptive frequency selection, L2 fitting\")\n",
    "print(f\"    - All observations used: {num_observed}\")\n",
    "print(f\"    - Computation time: {poly_time:.3f} seconds ({l1_time/poly_time:.1f}x faster)\")\n",
    "print(f\"    - Direct least squares (no iterative optimization)\")\n",
    "\n",
    "print(f\"\\n**Accuracy Comparison (Missing Points):**\")\n",
    "winner_rmse = \"L1\" if metrics_l1['rmse_missing'] < metrics_poly['rmse_missing'] else \"Polynomial\"\n",
    "winner_mae = \"L1\" if metrics_l1['mae_missing'] < metrics_poly['mae_missing'] else \"Polynomial\"\n",
    "winner_rel = \"L1\" if metrics_l1['rel_err_missing'] < metrics_poly['rel_err_missing'] else \"Polynomial\"\n",
    "\n",
    "print(f\"  RMSE:        L1={metrics_l1['rmse_missing']:.6f}  Poly={metrics_poly['rmse_missing']:.6f}  Winner: {winner_rmse}\")\n",
    "print(f\"  MAE:         L1={metrics_l1['mae_missing']:.6f}  Poly={metrics_poly['mae_missing']:.6f}  Winner: {winner_mae}\")\n",
    "print(f\"  Relative L2: L1={metrics_l1['rel_err_missing']:.6f}  Poly={metrics_poly['rel_err_missing']:.6f}  Winner: {winner_rel}\")\n",
    "\n",
    "# Determine overall winner\n",
    "l1_wins = sum([\n",
    "    metrics_l1['rmse_missing'] < metrics_poly['rmse_missing'],\n",
    "    metrics_l1['mae_missing'] < metrics_poly['mae_missing'],\n",
    "    metrics_l1['rel_err_missing'] < metrics_poly['rel_err_missing']\n",
    "])\n",
    "\n",
    "print(f\"\\n**Recommendation:**\")\n",
    "if l1_wins >= 2:\n",
    "    print(f\"  → L1 Minimization is MORE ACCURATE (wins {l1_wins}/3 metrics)\")\n",
    "    print(f\"  → But Polynomial is {l1_time/poly_time:.1f}x FASTER\")\n",
    "    print(f\"\\n  Use L1 if accuracy is critical, Polynomial for speed\")\n",
    "else:\n",
    "    print(f\"  → Polynomial Approximation is MORE ACCURATE (wins {3-l1_wins}/3 metrics)\")\n",
    "    print(f\"  → AND {l1_time/poly_time:.1f}x FASTER\")\n",
    "    print(f\"\\n  Recommendation: Use Polynomial Approximation\")\n",
    "\n",
    "print(f\"\\n**Key Insight:**\")\n",
    "print(f\"  The adaptive polynomial method selects frequencies that best\")\n",
    "print(f\"  explain the observed data, leading to excellent reconstruction\")\n",
    "print(f\"  for structured signals with low Fourier Ratio.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Verify Theoretical Bounds\n",
    "\n",
    "Check if L1 minimization satisfies Theorem 1.20 bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Theorem 1.20 bound for L1 method\n",
    "lhs, rhs, ratio, ok = check_theorem_bound(f_full, f_rec_l1, eps)\n",
    "\n",
    "print(\"\\n=== Theorem 1.20 Bound Verification (L1 Method) ===\")\n",
    "print(f\"||x* - f||₂         = {lhs:.6f}\")\n",
    "print(f\"11.47 × ||f||₂ × ε  = {rhs:.6f}\")\n",
    "print(f\"Ratio (lhs/rhs)     = {ratio:.4f}\")\n",
    "print(f\"\\nBound holds: {'✅ Yes' if ok else '❌ No'}\")\n",
    "if ok:\n",
    "    print(\"The L1 recovery satisfies the theoretical guarantee!\")\n",
    "else:\n",
    "    print(\"Try adjusting ε, C, or keep_prob parameters.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
