{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Value Recovery with Fourier Ratio and L1 Minimization\n",
    "\n",
    "This notebook demonstrates how to recover missing values in signals using the Fourier Ratio framework and compressed sensing techniques from the Talagrand constant paper.\n",
    "\n",
    "## Theory Overview\n",
    "\n",
    "**Theorem 1.20** states that if a signal has small Fourier Ratio FR, we can recover it from a small number of observations using L1 minimization.\n",
    "\n",
    "**Key Formula:**\n",
    "Number of observations needed:\n",
    "$$q = C \\times \\frac{FR^2}{\\epsilon^2} \\times \\log^2\\left(\\frac{FR}{\\epsilon}\\right) \\times \\log(N)$$\n",
    "\n",
    "**Recovery Guarantee:**\n",
    "$$\\|x^* - f\\|_2 \\leq 11.47 \\times \\|f\\|_2 \\times \\epsilon$$\n",
    "\n",
    "where $x^*$ is the recovered signal and $f$ is the true signal.\n",
    "\n",
    "**Method:**\n",
    "1. Represent signal in DCT (Discrete Cosine Transform) basis\n",
    "2. Solve L1 minimization: $\\min \\|c\\|_1$ subject to $Ac = y$ (observed values)\n",
    "3. Reconstruct signal from recovered coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nsys.path.insert(0, '..')\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Import our modules\nfrom src.fourier_core import fourier_ratio\nfrom src.imputation import (\n    mask_observations,\n    compute_q,\n    build_dct_basis,\n    recover_l1_via_lp,\n    check_theorem_bound\n)\nfrom src.signal_utils import sample_signal, plot_reconstruction, original_signal"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Test Signal and Simulate Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal parameters\n",
    "sr = 32  # sampling rate (Hz)\n",
    "seconds = 5.0  # duration\n",
    "N = int(sr * seconds)\n",
    "\n",
    "# Generate signal\n",
    "t, f_full = sample_signal(sr, seconds)\n",
    "\n",
    "# Compute Fourier Ratio\n",
    "FR = fourier_ratio(f_full)\n",
    "print(f\"Signal length N = {N}\")\n",
    "print(f\"Fourier Ratio FR = {FR:.4f}\")\n",
    "print(f\"Interpretation: {'Low complexity (good for recovery)' if FR < 5 else 'High complexity'}\")\n",
    "\n",
    "# Plot complete signal\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(t, f_full, 'b-', label='Complete signal')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Original Complete Signal')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate missing data\n",
    "keep_prob = 0.7  # Keep 70% of observations (30% missing)\n",
    "seed = 0  # for reproducibility\n",
    "\n",
    "mask, f_obs = mask_observations(f_full, keep_prob=keep_prob, seed=seed)\n",
    "\n",
    "num_observed = np.sum(mask)\n",
    "num_missing = np.sum(~mask)\n",
    "missing_rate = num_missing / N * 100\n",
    "\n",
    "print(f\"Total samples: {N}\")\n",
    "print(f\"Observed: {num_observed} ({100-missing_rate:.1f}%)\")\n",
    "print(f\"Missing: {num_missing} ({missing_rate:.1f}%)\")\n",
    "\n",
    "# Visualize observed vs missing\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(t, f_full, 'gray', alpha=0.3, label='True signal (hidden)')\n",
    "plt.scatter(t[mask], f_obs[mask], c='blue', s=15, label='Observed', zorder=3)\n",
    "plt.scatter(t[~mask], f_full[~mask], c='red', s=15, label='Missing', alpha=0.5, zorder=2)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title(f'Signal with {missing_rate:.1f}% Missing Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute Required Observations for Recovery\n",
    "\n",
    "Based on Theorem 1.20, we calculate how many observations are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recovery parameters\n",
    "eps = 0.1  # desired recovery accuracy\n",
    "C = 1.0  # universal constant multiplier\n",
    "\n",
    "valid_idx = np.where(mask)[0]\n",
    "q = compute_q(FR=FR, eps=eps, N=N, C=C, max_available=len(valid_idx))\n",
    "\n",
    "print(f\"Recovery parameters:\")\n",
    "print(f\"  ε (accuracy) = {eps}\")\n",
    "print(f\"  C (constant) = {C}\")\n",
    "print(f\"  FR = {FR:.4f}\")\n",
    "print(f\"\\nTheoretical observations needed: q = {q}\")\n",
    "print(f\"Available observations: {len(valid_idx)}\")\n",
    "print(f\"Formula: q = C × (FR²/ε²) × log²(FR/ε) × log(N)\")\n",
    "print(f\"       = {C} × ({FR:.2f}²/{eps}²) × log²({FR:.2f}/{eps}) × log({N})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Recover Missing Values using L1 Minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select q observations randomly\n",
    "np.random.seed(seed)\n",
    "obs_idx = np.random.choice(valid_idx, q, replace=False)\n",
    "y = f_obs[obs_idx]\n",
    "\n",
    "print(f\"Using {len(y)} observations for recovery\")\n",
    "\n",
    "# Build DCT basis\n",
    "B = build_dct_basis(N)\n",
    "\n",
    "# Create measurement matrix (only rows corresponding to observed indices)\n",
    "A = B[obs_idx, :]\n",
    "\n",
    "print(f\"Measurement matrix A shape: {A.shape}\")\n",
    "print(f\"Solving: min ||c||₁ subject to Ac = y\")\n",
    "\n",
    "# Solve L1 minimization\n",
    "c_rec = recover_l1_via_lp(A, y)\n",
    "\n",
    "# Reconstruct signal from coefficients\n",
    "f_rec = B @ c_rec\n",
    "\n",
    "print(f\"✓ Recovery complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Recovery Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute errors\n",
    "rel_err_full = np.linalg.norm(f_rec - f_full) / np.linalg.norm(f_full)\n",
    "rel_err_missing = np.linalg.norm(f_rec[~mask] - f_full[~mask]) / np.linalg.norm(f_full[~mask])\n",
    "\n",
    "print(\"Recovery Errors:\")\n",
    "print(f\"  Relative error (full signal):    {rel_err_full:.6f}\")\n",
    "print(f\"  Relative error (missing points): {rel_err_missing:.6f}\")\n",
    "\n",
    "# Check Theorem 1.20 bound\n",
    "lhs, rhs, ratio, ok = check_theorem_bound(f_full, f_rec, eps)\n",
    "\n",
    "print(\"\\n=== Theorem 1.20 Bound Verification ===\")\n",
    "print(f\"||x* - f||₂         = {lhs:.6f}\")\n",
    "print(f\"11.47 × ||f||₂ × ε  = {rhs:.6f}\")\n",
    "print(f\"Ratio (lhs/rhs)     = {ratio:.4f}\")\n",
    "print(f\"\\nBound holds: {'✅ Yes' if ok else '❌ No'}\")\n",
    "if ok:\n",
    "    print(\"The recovery satisfies the theoretical guarantee!\")\n",
    "else:\n",
    "    print(\"Try adjusting ε, C, or keep_prob parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Recovery Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstruction(t, f_full, mask, f_obs, f_rec, seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed view of reconstruction at missing points\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Full view\n",
    "axes[0].plot(t, f_full, 'k-', alpha=0.5, label='True signal')\n",
    "axes[0].scatter(t[mask], f_obs[mask], c='b', s=10, label='Observed', zorder=3)\n",
    "axes[0].plot(t[~mask], f_rec[~mask], 'ro', markersize=4, label='Recovered (missing)', zorder=4)\n",
    "axes[0].set_xlabel('Time (s)')\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "axes[0].set_title('Recovery: Observed vs Recovered Points')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Error view\n",
    "error_per_point = np.abs(f_rec - f_full)\n",
    "axes[1].plot(t, error_per_point, 'r-', alpha=0.5, label='Absolute error')\n",
    "axes[1].scatter(t[~mask], error_per_point[~mask], c='red', s=15, label='Error at missing points')\n",
    "axes[1].axhline(y=np.mean(error_per_point[~mask]), color='blue', linestyle='--', \n",
    "                label=f'Mean error (missing): {np.mean(error_per_point[~mask]):.4f}')\n",
    "axes[1].set_xlabel('Time (s)')\n",
    "axes[1].set_ylabel('Absolute Error')\n",
    "axes[1].set_title('Point-wise Recovery Error')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Parameter Sensitivity Analysis\n",
    "\n",
    "Let's explore how different parameters affect recovery quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Effect of Missing Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different missing rates\n",
    "keep_probs = [0.9, 0.8, 0.7, 0.6, 0.5]\n",
    "results_missing = []\n",
    "\n",
    "for kp in keep_probs:\n",
    "    mask_test, f_obs_test = mask_observations(f_full, keep_prob=kp, seed=seed)\n",
    "    valid_idx_test = np.where(mask_test)[0]\n",
    "    \n",
    "    q_test = compute_q(FR=FR, eps=eps, N=N, C=C, max_available=len(valid_idx_test))\n",
    "    \n",
    "    if q_test <= len(valid_idx_test):\n",
    "        obs_idx_test = np.random.choice(valid_idx_test, q_test, replace=False)\n",
    "        y_test = f_obs_test[obs_idx_test]\n",
    "        \n",
    "        A_test = B[obs_idx_test, :]\n",
    "        c_rec_test = recover_l1_via_lp(A_test, y_test)\n",
    "        f_rec_test = B @ c_rec_test\n",
    "        \n",
    "        rel_err_test = np.linalg.norm(f_rec_test - f_full) / np.linalg.norm(f_full)\n",
    "        \n",
    "        results_missing.append({\n",
    "            'keep_prob': kp,\n",
    "            'missing_rate': (1 - kp) * 100,\n",
    "            'q': q_test,\n",
    "            'rel_error': rel_err_test\n",
    "        })\n",
    "\n",
    "# Display results\n",
    "print(\"Missing Rate\\tObservations Used (q)\\tRelative Error\")\n",
    "print(\"=\"*60)\n",
    "for r in results_missing:\n",
    "    print(f\"{r['missing_rate']:.0f}%\\t\\t{r['q']}\\t\\t\\t{r['rel_error']:.6f}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot([r['missing_rate'] for r in results_missing], \n",
    "         [r['rel_error'] for r in results_missing], 'o-', markersize=8)\n",
    "plt.xlabel('Missing Rate (%)')\n",
    "plt.ylabel('Relative Recovery Error')\n",
    "plt.title('Recovery Quality vs Missing Rate')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Effect of Recovery Accuracy Parameter ε"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different epsilon values\n",
    "epsilon_values = [0.5, 0.3, 0.2, 0.1, 0.05]\n",
    "results_eps = []\n",
    "\n",
    "# Use fixed missing rate\n",
    "keep_prob_fixed = 0.7\n",
    "mask_fixed, f_obs_fixed = mask_observations(f_full, keep_prob=keep_prob_fixed, seed=seed)\n",
    "valid_idx_fixed = np.where(mask_fixed)[0]\n",
    "\n",
    "for eps_test in epsilon_values:\n",
    "    q_test = compute_q(FR=FR, eps=eps_test, N=N, C=C, max_available=len(valid_idx_fixed))\n",
    "    \n",
    "    if q_test <= len(valid_idx_fixed):\n",
    "        obs_idx_test = np.random.choice(valid_idx_fixed, q_test, replace=False)\n",
    "        y_test = f_obs_fixed[obs_idx_test]\n",
    "        \n",
    "        A_test = B[obs_idx_test, :]\n",
    "        c_rec_test = recover_l1_via_lp(A_test, y_test)\n",
    "        f_rec_test = B @ c_rec_test\n",
    "        \n",
    "        rel_err_test = np.linalg.norm(f_rec_test - f_full) / np.linalg.norm(f_full)\n",
    "        lhs_test, rhs_test, ratio_test, ok_test = check_theorem_bound(f_full, f_rec_test, eps_test)\n",
    "        \n",
    "        results_eps.append({\n",
    "            'eps': eps_test,\n",
    "            'q': q_test,\n",
    "            'rel_error': rel_err_test,\n",
    "            'bound_holds': ok_test\n",
    "        })\n",
    "\n",
    "# Display results\n",
    "print(f\"Fixed missing rate: {(1-keep_prob_fixed)*100:.0f}%\\n\")\n",
    "print(\"ε\\tObservations (q)\\tRel Error\\tBound Holds\")\n",
    "print(\"=\"*60)\n",
    "for r in results_eps:\n",
    "    print(f\"{r['eps']:.2f}\\t{r['q']}\\t\\t\\t{r['rel_error']:.6f}\\t{'✅' if r['bound_holds'] else '❌'}\")\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Observations vs epsilon\n",
    "ax1.plot([r['eps'] for r in results_eps], [r['q'] for r in results_eps], 'o-', markersize=8)\n",
    "ax1.set_xlabel('ε (accuracy parameter)')\n",
    "ax1.set_ylabel('Required observations q')\n",
    "ax1.set_title('Observations Needed vs Accuracy')\n",
    "ax1.grid(True)\n",
    "ax1.invert_xaxis()\n",
    "\n",
    "# Error vs epsilon\n",
    "ax2.plot([r['eps'] for r in results_eps], [r['rel_error'] for r in results_eps], 'o-', markersize=8)\n",
    "ax2.set_xlabel('ε (accuracy parameter)')\n",
    "ax2.set_ylabel('Achieved relative error')\n",
    "ax2.set_title('Recovery Error vs Accuracy Parameter')\n",
    "ax2.grid(True)\n",
    "ax2.invert_xaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparison with Naive Interpolation\n",
    "\n",
    "Let's compare L1 recovery with simple linear interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear interpolation for missing values\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Use only observed points for interpolation\n",
    "f_interp_func = interp1d(t[mask], f_obs[mask], kind='linear', fill_value='extrapolate')\n",
    "f_interp = f_interp_func(t)\n",
    "\n",
    "# Compute errors\n",
    "err_l1 = np.linalg.norm(f_rec - f_full) / np.linalg.norm(f_full)\n",
    "err_interp = np.linalg.norm(f_interp - f_full) / np.linalg.norm(f_full)\n",
    "\n",
    "print(\"Method Comparison:\")\n",
    "print(f\"L1 minimization (DCT):    {err_l1:.6f}\")\n",
    "print(f\"Linear interpolation:     {err_interp:.6f}\")\n",
    "print(f\"\\nL1 minimization is {err_interp/err_l1:.2f}x better\")\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(t, f_full, 'k-', alpha=0.4, label='True signal', linewidth=2)\n",
    "plt.scatter(t[mask], f_obs[mask], c='blue', s=15, label='Observed', zorder=3)\n",
    "plt.plot(t, f_rec, 'r--', label=f'L1 recovery (err={err_l1:.4f})', linewidth=2)\n",
    "plt.plot(t, f_interp, 'g-.', label=f'Linear interp (err={err_interp:.4f})', linewidth=2)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Comparison: L1 Minimization vs Linear Interpolation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Missing value simulation** - creating realistic scenarios with missing data\n",
    "2. **Theoretical analysis** - computing required observations based on Fourier Ratio\n",
    "3. **L1 minimization recovery** - using compressed sensing to recover missing values\n",
    "4. **Theorem verification** - checking Theorem 1.20 recovery bounds\n",
    "5. **Parameter sensitivity** - analyzing effects of missing rate and accuracy parameter\n",
    "6. **Method comparison** - L1 minimization vs simple interpolation\n",
    "\n",
    "**Key Parameters for Imputation:**\n",
    "\n",
    "| Parameter | Description | Typical Values |\n",
    "|-----------|-------------|----------------|\n",
    "| `FR` | Fourier Ratio (complexity measure) | 1 to √N |\n",
    "| `keep_prob` | Observation probability (1 - missing rate) | 0.6 - 0.8 |\n",
    "| `eps` | Recovery accuracy parameter | 0.1 - 0.5 |\n",
    "| `C` | Universal constant multiplier | 1.0 |\n",
    "| `q` | Number of observations for recovery | Computed from formula |\n",
    "| `N` | Signal length | Problem-dependent |\n",
    "| `seed` | Random seed for reproducibility | Any integer |\n",
    "\n",
    "**Key Insights:**\n",
    "- Signals with small FR can be recovered from few observations\n",
    "- L1 minimization outperforms naive interpolation for structured signals\n",
    "- The number of required observations scales as $q \\propto FR^2 \\log^2(FR) \\log(N)$\n",
    "- Recovery quality degrades gracefully with higher missing rates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}